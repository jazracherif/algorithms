{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max-spacing k-clustering.\n",
    "\n",
    "## Question 1\n",
    "\n",
    "In this programming problem and the next you'll code up the clustering algorithm from lecture for computing a max-spacing k-clustering.\n",
    "\n",
    "The file clustering1.txt describes a distance function (equivalently, a complete graph with edge costs). It has the following format:\n",
    "\n",
    "[number_of_nodes]\n",
    "\n",
    "[edge 1 node 1] [edge 1 node 2] [edge 1 cost]\n",
    "\n",
    "[edge 2 node 1] [edge 2 node 2] [edge 2 cost]\n",
    "\n",
    "...\n",
    "\n",
    "There is one edge (i,j) for each choice of 1≤i<j≤n, where n is the number of nodes.\n",
    "\n",
    "For example, the third line of the file is \"1 3 5250\", indicating that the distance between nodes 1 and 3 (equivalently, the cost of the edge (1,3)) is 5250. You can assume that distances are positive, but you should NOT assume that they are distinct.\n",
    "\n",
    "Your task in this problem is to run the clustering algorithm from lecture on this data set, where the target number k of clusters is set to 4. What is the maximum spacing of a 4-clustering?\n",
    "\n",
    "ADVICE: If you're not getting the correct answer, try debugging your algorithm using some small test cases. And then post them to the discussion forum!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union Find\n",
    "Implement the union find data structure with path compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class union_find_pc(object):    \n",
    "    def __init__(self, nodes):\n",
    "        self.leader = [i for i in range(len(nodes))]\n",
    "        self.rank = [0 for i in range(len(nodes))]\n",
    "        self.clusters = set([i for i in range(len(nodes))])\n",
    "        \n",
    "    def FIND(self, x):           \n",
    "        n = x\n",
    "        \n",
    "        while self.leader[n] != n:\n",
    "            n = self.leader[n]\n",
    "            \n",
    "        self.leader[x] = n   \n",
    "        return n\n",
    "     \n",
    "    def UNION(self, a, b):   \n",
    "        \n",
    "        a = self.FIND(a)\n",
    "        b = self.FIND(b)\n",
    "#         print (\"parent of a {} - parent of b {}\".format(a,b))\n",
    "        if (a == b):\n",
    "            return \n",
    "        \n",
    "        if (self.rank[a] == self.rank[b]):\n",
    "            # make a the leader of b and all its object            \n",
    "            flip = random.random() > 0.5\n",
    "#             print (\"flip\", flip)\n",
    "            if flip==1:\n",
    "                self.leader[b] = a                             \n",
    "                self.rank[a] += 1\n",
    "            else:\n",
    "                self.leader[a] = b                             \n",
    "                self.rank[b] += 1\n",
    "                \n",
    "        elif (self.rank[a] > self.rank[b]):\n",
    "            # make a the leader of b and all its object\n",
    "            self.leader[b] = a                             \n",
    "        else:\n",
    "            self.leader[a] = b \n",
    "            \n",
    "    def getClusters(self): \n",
    "        n_clusters = []\n",
    "        for i in range(len(self.leader)):\n",
    "            if self.leader[i] == i:\n",
    "                n_clusters.append(i)\n",
    "        return n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Union-Find data structure on a simple test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=UNION(0,1)\n",
      "0\n",
      "2\n",
      "leaders [0, 0, 2, 3, 4]\n",
      "rank [1, 0, 0, 0, 0]\n",
      "clusters [0, 2, 3, 4]\n",
      "=UNION(2,3)\n",
      "leaders [0, 0, 3, 3, 4]\n",
      "rank [1, 0, 0, 1, 0]\n",
      "clusters [0, 3, 4]\n",
      "=UNION(0,2)\n",
      "leaders [3, 0, 3, 3, 4]\n",
      "rank [1, 0, 0, 2, 0]\n",
      "clusters [3, 4]\n",
      "=UNION(0,4)\n",
      "leaders [3, 0, 3, 3, 3]\n",
      "rank [1, 0, 0, 2, 0]\n",
      "clusters [3]\n"
     ]
    }
   ],
   "source": [
    "obj = union_find_pc([0,1,2,3,4])\n",
    "\n",
    "print (\"=UNION(0,1)\")\n",
    "obj.UNION(0,1)\n",
    "print (obj.FIND(1))\n",
    "print (obj.FIND(2))\n",
    "print (\"leaders\", obj.leader)\n",
    "print (\"rank\", obj.rank)\n",
    "print (\"clusters\", obj.getClusters())\n",
    "\n",
    "print (\"=UNION(2,3)\")\n",
    "obj.UNION(2,3)\n",
    "print (\"leaders\", obj.leader)\n",
    "print (\"rank\", obj.rank)\n",
    "print (\"clusters\", obj.getClusters())\n",
    "\n",
    "print (\"=UNION(0,2)\")\n",
    "\n",
    "obj.UNION(0,2)\n",
    "print (\"leaders\", obj.leader)\n",
    "print (\"rank\", obj.rank)\n",
    "print (\"clusters\", obj.getClusters())\n",
    "\n",
    "print (\"=UNION(0,4)\")\n",
    "obj.UNION(0,4)\n",
    "print (\"leaders\", obj.leader)\n",
    "print (\"rank\", obj.rank)\n",
    "\n",
    "print (\"clusters\", obj.getClusters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final Clusters [125, 383, 413, 461]\n",
      "maximum spacing 106\n"
     ]
    }
   ],
   "source": [
    "FILE = \"./clustering1.txt\"\n",
    "# FILE = \"./clustering1-example-500-solution-2639.txt\"\n",
    "K =  4 \n",
    "fp = open(FILE, 'r')\n",
    "\n",
    "n_nodes = int(fp.readline())\n",
    "\n",
    "edges = []\n",
    "vertices = set()\n",
    "MAX_WEIGHT = 0\n",
    "\n",
    "for row in fp.readlines():\n",
    "    r = row.strip().split(\" \")\n",
    "    \n",
    "    vertices.add(int(r[0]))\n",
    "    vertices.add(int(r[1]))\n",
    "    weight = int(r[2])\n",
    "    if weight > MAX_WEIGHT:\n",
    "        MAX_WEIGHT = weight\n",
    "        \n",
    "    edges.append([int(r[0]),int(r[1]), int(r[2])])\n",
    "    \n",
    "sortedEdges = sorted(edges, key=lambda x: x[2])\n",
    "# print (sortedEdges)\n",
    "\n",
    "vertices = list(vertices)\n",
    "v_to_idx = {vertices[i]:i for i in range(len(vertices))}\n",
    "\n",
    "obj = union_find_pc([i for i in range(n_nodes)])\n",
    "\n",
    "for i, edge in enumerate(sortedEdges):  \n",
    "    v1 = v_to_idx[edge[0]]\n",
    "    v2 = v_to_idx[edge[1]]\n",
    "    w = edge[2]\n",
    "    \n",
    "    obj.UNION(v1, v2)\n",
    "    \n",
    "    if len(obj.getClusters()) == 4:\n",
    "        print (\"final Clusters\", obj.getClusters())\n",
    "        break\n",
    "        \n",
    "minW = MAX_WEIGHT\n",
    "for i, edge in enumerate(sortedEdges):  \n",
    "    v1 = v_to_idx[edge[0]]\n",
    "    v2 = v_to_idx[edge[1]]\n",
    "    w = edge[2]\n",
    "    \n",
    "    if obj.FIND(v1) != obj.FIND(v2):\n",
    "        if w < minW:\n",
    "            minW = w\n",
    "print (\"maximum spacing\", minW)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "in this question your task is again to run the clustering algorithm from lecture, but on a MUCH bigger graph. So big, in fact, that the distances (i.e., edge costs) are only defined implicitly, rather than being provided as an explicit list.\n",
    "\n",
    "The data set is below. clustering_big.txt\n",
    "\n",
    "The format is:\n",
    "\n",
    "[# of nodes] [# of bits for each node's label]\n",
    "\n",
    "[first bit of node 1] ... [last bit of node 1]\n",
    "\n",
    "[first bit of node 2] ... [last bit of node 2]\n",
    "\n",
    "...\n",
    "\n",
    "For example, the third line of the file \"0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1\" denotes the 24 bits associated with node #2.\n",
    "\n",
    "The distance between two nodes u and v in this problem is defined as the Hamming distance--- the number of differing bits --- between the two nodes' labels. For example, the Hamming distance between the 24-bit label of node #2 above and the label \"0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1\" is 3 (since they differ in the 3rd, 7th, and 21st bits).\n",
    "\n",
    "The question is: what is the largest value of k such that there is a k-clustering with spacing at least 3? That is, how many clusters are needed to ensure that no pair of nodes with all but 2 bits in common get split into different clusters?\n",
    "\n",
    "NOTE: The graph implicitly defined by the data file is so big that you probably can't write it out explicitly, let alone sort the edges by cost. So you will have to be a little creative to complete this part of the question. For example, is there some way you can identify the smallest distances without explicitly looking at every pair of nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def distance_0_items(data):\n",
    "    dist0_present = collections.defaultdict(list)\n",
    "    dist0_keys = collections.defaultdict(list)\n",
    "    dist0_list = []\n",
    "    for i, d in enumerate(data):\n",
    "        if d in dist0_keys:\n",
    "            dist0_present[d].append(i)\n",
    "        else:\n",
    "            dist0_keys[d] = i\n",
    "\n",
    "    for d in dist0_present:\n",
    "        dist0_present[d].append(dist0_keys[d])\n",
    "\n",
    "    for k, d in dist0_present.items():    \n",
    "        # create all combinations of 2 items which match the key\n",
    "        out = combinations(d, 2)\n",
    "        for c in out:\n",
    "            dist0_list.append([c[0], c[1]])\n",
    "\n",
    "    return dist0_list\n",
    "\n",
    "def distance_1_items(data, n_bits):\n",
    "    \n",
    "    def dist_1(a, n_bits, out, index=None):\n",
    "        for i in range(n_bits):\n",
    "            dist_1 = int(a,2) ^ (1 << i)   \n",
    "            # many nodes will generate similar other nodes of distance 1 from themselves\n",
    "            out[dist_1].append(index)  \n",
    "            \n",
    "    dist1_present = collections.defaultdict(list)\n",
    "    dist1_keys = collections.defaultdict(list)\n",
    "    dist1_list = []\n",
    "    \n",
    "    # For each node, generate all other nodes with distance 1 and their idx in a hash table list\n",
    "    # If a later node is found in the list, then add it to the dist1_present\n",
    "    for i, d in enumerate(data):\n",
    "        d_val = int(d,2)\n",
    "        if d_val in dist1_keys:\n",
    "            # nodes of distance 1 to d exists, store it in dist1_present\n",
    "            dist1_present[d_val].append(i)\n",
    "        dist_1(d, n_bits, dist1_keys, i)\n",
    "\n",
    "    for key, val in dist1_present.items():\n",
    "        # create all combinations of 2 items which match the key\n",
    "        for d in val:\n",
    "            for c in dist1_keys[key]:\n",
    "                dist1_list.append([d, c])\n",
    "\n",
    "    return dist1_list\n",
    "\n",
    "\n",
    "def distance_2_items(data, n_bits):\n",
    "    def dist_2(a, n_bits, out, index=None):\n",
    "        for i in range(0,n_bits-1):\n",
    "            for j in range(i+1, n_bits):\n",
    "                dist_2 = int(a,2) ^ (1 << i)     \n",
    "                dist_2 = dist_2 ^ (1 << j)     \n",
    "                # many nodes will generate similar other nodes of distance 2 from themselves\n",
    "                out[dist_2].append(index)  \n",
    "        \n",
    "    dist2_present = collections.defaultdict(list)\n",
    "    dist2_keys = collections.defaultdict(list)\n",
    "    dist2_list = []\n",
    "    \n",
    "    # For each node, generate all other nodes with distance 1 and their idx in a hash table list\n",
    "    # If a later node is found in the list, then add it to the dist1_present\n",
    "    for i, d in enumerate(data):\n",
    "        d_val = int(d,2)\n",
    "        if d_val in dist2_keys:\n",
    "            # nodes of distance 1 to d exists, store it in dist1_present\n",
    "            dist2_present[d_val].append(i)\n",
    "        dist_2(d, n_bits, dist2_keys, i)\n",
    "\n",
    "    for key, val in dist2_present.items():\n",
    "        # create all combinations of 2 items which match the key\n",
    "        for d in val:\n",
    "            for c in dist2_keys[key]:\n",
    "                dist2_list.append([d, c])\n",
    "\n",
    "    return dist2_list\n",
    "    \n",
    "def solve_p2(data, n_bits, n_nodes):\n",
    "    dist0_list = distance_0_items(data)\n",
    "    dist1_list = distance_1_items(data, n_bits)\n",
    "    dist2_list = distance_2_items(data, n_bits)\n",
    "\n",
    "    obj = union_find_pc([i for i in range(n_nodes)])\n",
    "    for i, edge in enumerate(dist0_list):  \n",
    "        v1 = edge[0]\n",
    "        v2 = edge[1]    \n",
    "        obj.UNION(v1, v2)\n",
    "\n",
    "    for i, edge in enumerate(dist1_list):  \n",
    "        v1 = edge[0]\n",
    "        v2 = edge[1]    \n",
    "        obj.UNION(v1, v2)\n",
    "\n",
    "    for i, edge in enumerate(dist2_list):  \n",
    "        v1 = edge[0]\n",
    "        v2 = edge[1]    \n",
    "        obj.UNION(v1, v2)\n",
    "\n",
    "    # After clustering together all points of 0, 1, and 2 distance, we get all those points together and all\n",
    "    # remaining one are further away. Each other point being its own cluster, \n",
    "    # this is the max number of clusters total\n",
    "    return len(obj.getClusters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED ALL TESTS!\n"
     ]
    }
   ],
   "source": [
    "TEST_CASES = [  \n",
    "                [\"./clustering2-example-200-12-solution-4.txt\", 4],\n",
    "                [\"./clustering2-example-200-12-solution-6.txt\", 6],\n",
    "                [\"clustering2-example-2000-24-solution-1575.txt\", 1575]\n",
    "             ]\n",
    "\n",
    "for test in TEST_CASES:\n",
    "    file = test[0]\n",
    "    solution = test[1]\n",
    "    \n",
    "    fp = open(file, 'r')\n",
    "    n_nodes, n_bits = fp.readline().strip().split(\" \")\n",
    "    n_nodes, n_bits = int(n_nodes), int(n_bits)\n",
    "\n",
    "    data = []\n",
    "    for row in fp.readlines():\n",
    "        a = \"\".join(row.strip().split(\" \"))\n",
    "        data.append(a)\n",
    "\n",
    "    solved = solve_p2(data, n_bits, n_nodes)\n",
    "\n",
    "    assert (solved == solution), (\"Expected {}, got {}, file {}\").format(solution, solved, file)\n",
    "    \n",
    "print (\"PASSED ALL TESTS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"./clustering_big.txt\"\n",
    "\n",
    "fp = open(FILE, 'r')\n",
    "n_nodes, n_bits = fp.readline().strip().split(\" \")\n",
    "n_nodes, n_bits = int(n_nodes), int(n_bits)\n",
    "\n",
    "data = []\n",
    "for row in fp.readlines():\n",
    "    a = \"\".join(row.strip().split(\" \"))\n",
    "    data.append(a)\n",
    "\n",
    "solved = solve_p2(data, n_bits, n_nodes)\n",
    "\n",
    "print (\"P2 Solution\", solved)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
